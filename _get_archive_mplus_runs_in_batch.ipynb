{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import importlib\n",
    "import blizzard_api\n",
    "import mysql\n",
    "import mplusdb\n",
    "import blizzard_credentials\n",
    "import pandas as pd\n",
    "import utils\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mplusdb)\n",
    "mdb = mplusdb.MplusDatabase('.db_config')\n",
    "realms = mdb.get_utility_table('realm')\n",
    "dungeons = mdb.get_utility_table('dungeon')\n",
    "specs = mdb.get_utility_table('spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realm_clusters = realms[['cluster_id', 'region']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = blizzard_credentials.Credentials('.api_tokens')\n",
    "access_token = auth.access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a bit anti-pattern, but the fastest way\n",
    "\n",
    "# generate url calls for every valid combination of\n",
    "# region/realm_cluster/dungeon/period\n",
    "\n",
    "# S4 starts with period 734\n",
    "region_encoder = {1:'us', 2:'kr', 3:'eu', 4:'tw'}\n",
    "\n",
    "all_urls = []\n",
    "urls_for_period_region_dungeon = {}\n",
    "for _, row in dungeons.iterrows():\n",
    "    dungeon_id = row[0]\n",
    "    if dungeon_id < 244:\n",
    "        continue;\n",
    "    period_start = 734 #row[2]\n",
    "    period_end = 763\n",
    "    for _, realm in realm_clusters.iterrows():\n",
    "        cluster_id = realm[0]\n",
    "        region = region_encoder[realm[1]]\n",
    "        url_factory = blizzard_api.UrlFactory(\n",
    "            access_token = access_token, region=region)\n",
    "        for period in range(period_start, period_end+1):\n",
    "            url = url_factory.get_mythic_plus_leaderboard_url(\n",
    "                dungeon_id = dungeon_id, realm_id = cluster_id,\n",
    "                period = period)\n",
    "            all_urls.append(url)\n",
    "            #assign url to a sub-list by region-period\n",
    "            key = (region, period, dungeon_id)\n",
    "            if key in urls_for_period_region_dungeon:\n",
    "                urls_for_period_region_dungeon[key].append(url)\n",
    "            else:\n",
    "                urls_for_period_region_dungeon[key] = []\n",
    "                urls_for_period_region_dungeon[key].append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls_for_period_region_dungeon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check math by hand\n",
    "calls_per_realm = (10 * (764-662)) + (33 * 2)\n",
    "print('calls per realm', calls_per_realm)\n",
    "print('total calls', calls_per_realm * len(realm_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total time (hrs):', len(all_urls) * 0.25 / 3600)\n",
    "print('total space raw json (Gbs):', 1/1024 * 1.2 * len(all_urls))\n",
    "print('total space python list (Gbs):', 1/1024 * 0.02 * len(all_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How are we going to do this?\n",
    "\n",
    "So we got 284,000 url calls we need to make. Each call takes on ~0.25 seconds on average (if we use 10 threads), and generates 1.2Mb of data.\n",
    "\n",
    "```\n",
    "Total data size = 273,304 * 1.2Mb = 320 Gb\n",
    "```\n",
    "\n",
    "The capacity of my DB is just 20Gb. Oh-oh. I don't even have the storage for this.\n",
    "\n",
    "#### Is it really 1.2Mb per call? I don't think so:\n",
    "\n",
    "The raw json is 1.2Mb. Once we extract the data, the list is only 20kb. So total is:\n",
    "\n",
    "```\n",
    "Total data size = 273,304 * 0.02Mb = 5 Gb\n",
    "```\n",
    "\n",
    "I have plenty of space for this. Yay. Let's proceed.\n",
    "\n",
    "#### This is how we are going to proceed:\n",
    "* Break up the API calls into segments based on region and time period. Each segment is a time period within a region, and there are 404 total segments.\n",
    "* Query each segment, one at a time.\n",
    "* Aggregate data for each segment, and push to DB\n",
    "* Keep track of which segment is done using some form of logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "class MyLogger():\n",
    "    \"\"\"wrapper for a simple logger\"\"\"\n",
    "    __fp = 'logs/mdb_segments.log'\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log(self, segment_id):\n",
    "        ts = time.time()\n",
    "        ts = datetime.datetime.fromtimestamp(ts).strftime('%c')\n",
    "        with open(self.__fp, 'a') as file:\n",
    "            #file.write('%s\\t%s\\t%s\\t%s\\n' % (ts, segment_id))\n",
    "            file.write('%s\\t%s\\n' % (ts, segment_id))\n",
    "            \n",
    "    def get_logged_keys(self):\n",
    "        keys = []\n",
    "        with open(self.__fp, 'r') as file:\n",
    "            for line in file:\n",
    "                key_token = line.split()[-1]\n",
    "                key = key_token.split('_')\n",
    "                keys.append((key[0], int(key[1]), int(key[2])))\n",
    "        return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = MyLogger()\n",
    "logged_keys = logger.get_logged_keys()\n",
    "print(len(logged_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(87.0/1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chunks(list_, n): \n",
    "    # looping till length l \n",
    "    for i in range(0, len(list_), n):  \n",
    "        yield list_[i:i + n] \n",
    "        \n",
    "list(divide_chunks(list(range(10)), 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(blizzard_api)\n",
    "importlib.reload(mplusdb)\n",
    "\n",
    "def divide_chunks(list_, n): \n",
    "    # looping till length l \n",
    "    for i in range(0, len(list_), n):  \n",
    "        yield list_[i:i + n] \n",
    "        \n",
    "        \n",
    "def api_call(url):\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        response = requests.get(url, timeout = 10)\n",
    "    except:\n",
    "        response = requests.get(url)\n",
    "    #print(time.time())\n",
    "    #response = 0\n",
    "    return response\n",
    "\n",
    "def api_call_session(urls):\n",
    "    responses = []\n",
    "    with requests.Session() as session:\n",
    "        for url in urls:\n",
    "            try:\n",
    "                response = session.get(url, timeout = 10)\n",
    "            except: \n",
    "                response = session.get(url, timeout = 10)\n",
    "            responses.append(response)\n",
    "    return responses\n",
    "\n",
    "def multi_threaded_call_chunked(urls):\n",
    "    \"\"\"Sends multiple calls to the API at once.\"\"\"\n",
    "    \n",
    "    #chunk the urls into pieces with 10 urls each\n",
    "    url_chunks = divide_chunks(urls, 10)\n",
    "        \n",
    "    threads = []\n",
    "    with ThreadPoolExecutor(max_workers = 10) as executor:\n",
    "        for chunk in url_chunks:\n",
    "            threads.append(executor.submit(api_call_session, chunk))\n",
    "    agg_result = []\n",
    "    for task in as_completed(threads):\n",
    "        agg_result.extend(task.result())\n",
    "    return agg_result\n",
    "    \n",
    "\n",
    "def multi_threaded_call(urls):\n",
    "    \"\"\"Sends multiple calls to the API at once.\"\"\"\n",
    "    threads = []\n",
    "    with ThreadPoolExecutor(max_workers = 10) as executor:\n",
    "        for url in urls:\n",
    "            threads.append(executor.submit(api_call, url))\n",
    "    agg_result = []\n",
    "    for task in as_completed(threads):\n",
    "        agg_result.append(task.result())\n",
    "    return agg_result\n",
    "\n",
    "\n",
    "def agg_leaderboards(responses):\n",
    "    \"\"\"Joins output of several leaderboards into single list.\"\"\"\n",
    "    parser = blizzard_api.ResponseParser()\n",
    "    \n",
    "    runs = []\n",
    "    comps = []\n",
    "    rosters = []\n",
    "            \n",
    "    for resp in responses:\n",
    "        leaderboard = parser.parse_keyrun_leaderboard_json(resp.json())\n",
    "        runs.extend(leaderboard.get_runs_as_tuple_list())\n",
    "        rosters.extend(leaderboard.get_rosters_as_tuple_list())\n",
    "        comps.extend(leaderboard.get_run_comps_as_vector_list())\n",
    "    \n",
    "    return runs, comps, rosters\n",
    "\n",
    "mdb = mplusdb.MplusDatabase('.db_config')\n",
    "\n",
    "segment = []\n",
    "t0 = time.time()\n",
    "i = 0\n",
    "\n",
    "logger = MyLogger()\n",
    "logged_keys = logger.get_logged_keys() # segments already done\n",
    "\n",
    "for key, urls in urls_for_period_region_dungeon.items():\n",
    "    if key in logged_keys:\n",
    "        i += 1\n",
    "        print(key, i)\n",
    "        continue\n",
    "    print(key)\n",
    "    print(len(urls))\n",
    "    print(datetime.datetime.now())\n",
    "    t00 = time.time()\n",
    "    responses = None\n",
    "    #responses = multi_threaded_call(urls)\n",
    "    responses = multi_threaded_call_chunked(urls)\n",
    "    t1 = time.time()\n",
    "    print('api calls', t1 - t00)\n",
    "    runs, comps, rosters = agg_leaderboards(responses)\n",
    "    t2 = time.time()\n",
    "    print('parsing jsons', t2 - t1)\n",
    "    runs = list(set(runs))\n",
    "    rosters = list(set(rosters))\n",
    "    comps = list(set(comps))\n",
    "    t3 = time.time()\n",
    "    print('set(data)', t3 - t2)\n",
    "    \n",
    "    \n",
    "    mdb.insert(table = 'run', data = runs)\n",
    "    t4 = time.time()\n",
    "    print('inserting runs', t4 - t3)\n",
    "    \n",
    "    mdb.insert(table = 'roster', data = rosters)\n",
    "    t5 = time.time()\n",
    "    print('inserting rosters', t5 - t4)\n",
    "    \n",
    "    mdb.insert(table = 'run_composition', data = comps)\n",
    "    t5 = time.time()\n",
    "    print('inserting comps', t5 - t4)\n",
    "    \n",
    "    print(len(runs))\n",
    "    print(len(comps))\n",
    "    print(len(rosters))\n",
    "    i += 1\n",
    "    logger.log('%s_%s_%s' % key)\n",
    "    print('-------------------')\n",
    "    if i % 10 == 0:\n",
    "        time.sleep(2)\n",
    "    if i == 500:\n",
    "        break\n",
    "print('total', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rq.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5*1440/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(blizzard_api)\n",
    "all_urls[0]\n",
    "\n",
    "t0 = time.time()\n",
    "test_rq = requests.get(all_urls[0])\n",
    "print(time.time() - t0)\n",
    "test_klb = blizzard_api.KeyRunLeaderboard(test_rq.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_klb.keyruns[0].get_composition_vector()\n",
    "t0 = time.time()\n",
    "comps = test_klb.get_run_comps_as_vector_list()\n",
    "print(time.time()-t0)\n",
    "print(comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(comps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(leaderboard.get_runs_as_tuple_list(), open('test_objs.pkl', 'wb'))\n",
    "#print(leaderboard.keyruns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
